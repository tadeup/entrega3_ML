{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DividendStocks</th>\n",
       "      <th>EmergingMarkets</th>\n",
       "      <th>ForeignStocks</th>\n",
       "      <th>MunicipalBonds</th>\n",
       "      <th>NaturalResources</th>\n",
       "      <th>RiskTolerance</th>\n",
       "      <th>USStocks</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>q6</th>\n",
       "      <th>q7</th>\n",
       "      <th>q8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>17940000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>67714000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>68527000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>50352000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>93291000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34119000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>83735000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>93350000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>19398000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>75739000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DividendStocks  EmergingMarkets  ForeignStocks  MunicipalBonds  \\\n",
       "0            0.05             0.11           0.14            0.33   \n",
       "1            0.05             0.28           0.22            0.05   \n",
       "2            0.07             0.09           0.13            0.35   \n",
       "3            0.05             0.11           0.14            0.33   \n",
       "4            0.05             0.28           0.22            0.05   \n",
       "\n",
       "   NaturalResources  RiskTolerance  USStocks  q1  q2  q3          q4  q5  \\\n",
       "0              0.05          0.045      0.32   1   4  95  17940000.0   2   \n",
       "1              0.05          0.100      0.35   4   2  33  68527000.0   4   \n",
       "2              0.06          0.040      0.30   2   1  71  93291000.0   4   \n",
       "3              0.05          0.045      0.32   1   3  89  83735000.0   5   \n",
       "4              0.05          0.100      0.35   1   4  52  19398000.0   1   \n",
       "\n",
       "           q6  q7  q8  \n",
       "0  67714000.0   2   4  \n",
       "1  50352000.0   1   4  \n",
       "2  34119000.0   2   3  \n",
       "3  93350000.0   2   4  \n",
       "4  75739000.0   1   4  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dados = pd.read_csv('wealthfront.csv')\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dados[\"RiskTolerance\"].values\n",
    "y = (y*1000).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [col for col in dados if col.startswith('q')]\n",
    "X = dados[x].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1,...f',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf), ('lr', log_clf), ('tree', tree_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17 (+/- 0.01) [KNN]\n",
      "Accuracy: 0.24 (+/- 0.00) [Reg Logistica]\n",
      "Accuracy: 0.96 (+/- 0.00) [tree]\n",
      "Accuracy: 0.24 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.26 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([knn_clf, log_clf, tree_clf, svm_clf, voting_clf], ['KNN', 'Reg Logistica', 'tree', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1,...bf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(random_state=42, probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf), ('lr', log_clf), ('tree', tree_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17 (+/- 0.01) [KNN]\n",
      "Accuracy: 0.24 (+/- 0.00) [Reg Logistica]\n",
      "Accuracy: 0.47 (+/- 0.00) [tree]\n",
      "Accuracy: 0.24 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.41 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([knn_clf, log_clf, tree_clf, svm_clf, voting_clf], ['KNN', 'Reg Logistica', 'tree', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tadeu\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          5       0.21      0.50      0.29        10\n",
      "         10       0.00      0.00      0.00         2\n",
      "         15       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         5\n",
      "         30       0.04      0.10      0.06        10\n",
      "         35       0.08      0.15      0.10        89\n",
      "         40       0.21      0.36      0.27       234\n",
      "         45       0.13      0.11      0.12       152\n",
      "         50       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         5\n",
      "         70       0.03      0.01      0.02        76\n",
      "         75       0.00      0.00      0.00         6\n",
      "         80       0.17      0.12      0.14       147\n",
      "         85       0.17      0.05      0.08        75\n",
      "         90       0.00      0.00      0.00        73\n",
      "         95       0.00      0.00      0.00         3\n",
      "        100       0.14      0.07      0.09        70\n",
      "\n",
      "avg / total       0.13      0.15      0.13       966\n",
      "\n",
      "LogisticRegression \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          5       0.43      0.30      0.35        10\n",
      "         10       0.00      0.00      0.00         2\n",
      "         15       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         5\n",
      "         30       0.00      0.00      0.00        10\n",
      "         35       0.00      0.00      0.00        89\n",
      "         40       0.24      1.00      0.39       234\n",
      "         45       0.00      0.00      0.00       152\n",
      "         50       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         5\n",
      "         70       0.00      0.00      0.00        76\n",
      "         75       0.00      0.00      0.00         6\n",
      "         80       0.00      0.00      0.00       147\n",
      "         85       0.00      0.00      0.00        75\n",
      "         90       0.00      0.00      0.00        73\n",
      "         95       0.00      0.00      0.00         3\n",
      "        100       0.00      0.00      0.00        70\n",
      "\n",
      "avg / total       0.06      0.24      0.10       966\n",
      "\n",
      "DecisionTreeClassifier \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          5       0.00      0.00      0.00        10\n",
      "         10       0.00      0.00      0.00         2\n",
      "         15       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         5\n",
      "         30       0.00      0.00      0.00        10\n",
      "         35       0.00      0.00      0.00        89\n",
      "         40       0.46      0.98      0.63       234\n",
      "         45       0.39      1.00      0.56       152\n",
      "         50       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         5\n",
      "         70       0.00      0.00      0.00        76\n",
      "         75       0.00      0.00      0.00         6\n",
      "         80       0.00      0.00      0.00       147\n",
      "         85       0.95      1.00      0.97        75\n",
      "         90       0.00      0.00      0.00        73\n",
      "         95       0.00      0.00      0.00         3\n",
      "        100       0.00      0.00      0.00        70\n",
      "\n",
      "avg / total       0.25      0.47      0.32       966\n",
      "\n",
      "SVC \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          5       0.00      0.00      0.00        10\n",
      "         10       0.00      0.00      0.00         2\n",
      "         15       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         5\n",
      "         30       0.00      0.00      0.00        10\n",
      "         35       0.00      0.00      0.00        89\n",
      "         40       0.24      1.00      0.39       234\n",
      "         45       0.00      0.00      0.00       152\n",
      "         50       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         5\n",
      "         70       0.00      0.00      0.00        76\n",
      "         75       0.00      0.00      0.00         6\n",
      "         80       0.00      0.00      0.00       147\n",
      "         85       0.00      0.00      0.00        75\n",
      "         90       0.00      0.00      0.00        73\n",
      "         95       0.00      0.00      0.00         3\n",
      "        100       0.00      0.00      0.00        70\n",
      "\n",
      "avg / total       0.06      0.24      0.09       966\n",
      "\n",
      "VotingClassifier \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          5       0.00      0.00      0.00        10\n",
      "         10       0.00      0.00      0.00         2\n",
      "         15       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         5\n",
      "         30       0.00      0.00      0.00        10\n",
      "         35       0.00      0.00      0.00        89\n",
      "         40       0.36      0.96      0.53       234\n",
      "         45       0.46      0.62      0.53       152\n",
      "         50       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         5\n",
      "         70       0.00      0.00      0.00        76\n",
      "         75       0.00      0.00      0.00         6\n",
      "         80       0.39      0.13      0.19       147\n",
      "         85       0.94      0.89      0.92        75\n",
      "         90       0.17      0.01      0.03        73\n",
      "         95       0.00      0.00      0.00         3\n",
      "        100       0.46      0.09      0.14        70\n",
      "\n",
      "avg / total       0.34      0.43      0.32       966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tadeu\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for clf in (knn_clf, log_clf, tree_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, '\\n\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_small = RandomForestClassifier(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_small = rf_small.estimators_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
